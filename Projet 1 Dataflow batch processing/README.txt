Dataflow ‚Äì GCS ‚Üí BigQuery (Template + UDF)
üéØ Description

Ce projet contient les fichiers utilis√©s pour cr√©er un job Google Cloud Dataflow via l‚Äôinterface GCP, en utilisant le template ‚ÄúGCS Text to BigQuery‚Äù.
Le pipeline lit des fichiers CSV dans Cloud Storage, applique une UDF JavaScript pour transformer les donn√©es, puis charge le r√©sultat dans une table BigQuery selon un sch√©ma d√©fini.

Ce repo documente :

la UDF JavaScript utilis√©e dans le job

le sch√©ma BigQuery (schema.json)

un exemple de fichier source CSV

les instructions pour reproduire le job Dataflow

üß∞ Comment reproduire le job (via Console GCP)

Uploader dans ton bucket GCS :

input/*.csv (tes donn√©es source)

schema.json (sch√©ma BigQuery)

udf.js (fonction JavaScript)

un dossier tmp/ pour les fichiers temporaires du job

Cr√©er un job Dataflow

Aller dans Dataflow > Cr√©er un job √† partir d‚Äôun template

Template : Text File on Cloud Storage to BigQuery

Param√®tres √† renseigner :

inputFilePattern : gs://<bucket>/input/*.csv

outputTableSpec : <PROJECT_ID>:<DATASET>.<TABLE>

schemaPath : gs://<bucket>/schema.json

javascriptTextTransformGcsPath : gs://<bucket>/udf.js

javascriptTextTransformFunctionName : transform

bigQueryLoadingTemporaryDirectory : gs://<bucket>/temp/

Lancer le job et v√©rifier dans :

Dataflow ‚Üí statut du job

BigQuery ‚Üí que la table contient bien les donn√©es